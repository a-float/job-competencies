{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "data = None\n",
    "with open('./data/job_offers.json', 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    data = json.loads(text)\n",
    "# print(json.dumps(data[0], indent=4, ensure_ascii=False))\n",
    "\n",
    "musts = []\n",
    "nices = []\n",
    "langs = []\n",
    "for item in data:\n",
    "    musts.extend(item[\"requirements\"][\"musts\"])\n",
    "    nices.extend(item[\"requirements\"][\"nices\"])\n",
    "    langs.extend(item[\"requirements\"][\"languages\"])\n",
    "print(f\"Offers: {len(data)}\\nMust have requirements: {len(musts)}\\nNice to have requirements {len(nices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musts[162]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nices[235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[423][\"essentials\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_salaries(item):\n",
    "    currency = item[\"essentials\"][\"salary\"][\"currency\"]\n",
    "    if currency != \"PLN\":\n",
    "        return []\n",
    "    types = item[\"essentials\"][\"salary\"][\"types\"]\n",
    "    salaries = []\n",
    "    for contract in [\"permanent\", \"b2b\"]:\n",
    "        if contract not in types:\n",
    "            continue\n",
    "        if types[contract][\"period\"] != \"Month\":\n",
    "            continue\n",
    "        range = types[contract][\"range\"]\n",
    "        if len(range) != 2:\n",
    "            continue\n",
    "        salaries.append({\"contract\": contract, \"currency\":  currency, \"avg\": sum(map(int, range)) / len(range)})\n",
    "    return salaries\n",
    "\n",
    "\n",
    "def plot_against_salary(data, title, box_contract = None):\n",
    "    if box_contract not in [None, \"permanent\", \"b2b\"]:\n",
    "        raise ValueError(\"Invalid box_contract value\")\n",
    "    \n",
    "    grouped = defaultdict(lambda: [])\n",
    "    for item in data:\n",
    "        attr = \"Remote\" if item[\"location\"][\"remote\"] else \"Non-remote\"\n",
    "        salaries = get_avg_salaries(item)\n",
    "        grouped[attr].extend(salaries)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=len(grouped), ncols=1, figsize=(10, 6.5))\n",
    "    fig.subplots_adjust(hspace=0.4)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    for [ax, [key, group]] in zip(axes, grouped.items()):\n",
    "        permanent_means = [salary[\"avg\"] for salary in group if salary[\"contract\"] == \"permanent\"]\n",
    "        b2b_means = [salary[\"avg\"] for salary in group if salary[\"contract\"] == \"b2b\"]\n",
    "        labels = [\"permanent\", \"b2b\"]\n",
    "        colors = [\"C0\", \"C1\"]\n",
    "        for i, means in enumerate([permanent_means, b2b_means]): \n",
    "            print(f\"Plotting {len(means)} {key} {labels[i]} records.\")\n",
    "            if box_contract:\n",
    "                if labels[i] != box_contract:\n",
    "                    continue\n",
    "                ax.boxplot(means, vert=False)\n",
    "                ax.get_yaxis().set_visible(False)\n",
    "                ax.set_title(f\"{key} {box_contract}\")\n",
    "            else:\n",
    "                counts, bins = np.histogram(means, 20)\n",
    "                ax.stairs(counts, bins, label=labels[i], color=colors[i])\n",
    "                ax.axvline(np.mean(means), linestyle='dashed', color=colors[i], linewidth=1, label=f\"{labels[i]} mean\")\n",
    "                ax.set_ylabel(\"Number of occurances\")\n",
    "                ax.set_title(key)\n",
    "                ax.legend()\n",
    "\n",
    "        ax.set_xlim(-1, 55_000)\n",
    "        ax.set_xlabel(\"Range average salary [PLN]\")\n",
    "\n",
    "\n",
    "plot_against_salary(data, title=\"Salary vs remote work\")\n",
    "# plot_against_salary(data, box_contract=\"b2b\", title=\"B2b salary vs remote work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Requirements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reqs(reqs, title, col=\"plasma\"):\n",
    "    counter = Counter([m[\"value\"] for m in reqs])\n",
    "    names = sorted(list(counter), key=lambda x: -counter[x])[:50]\n",
    "    names = list(reversed(names))\n",
    "    values = [counter[name] for name in names]\n",
    "\n",
    "    if col == \"plasma\":\n",
    "        gradient = np.linspace(0, 0.7, len(names))\n",
    "        colors = plt.cm.plasma(gradient)\n",
    "    else:\n",
    "        gradient = np.linspace(0, 0.7, len(names))\n",
    "        colors = plt.cm.viridis(gradient)\n",
    "        \n",
    "    plt.figure(figsize=(12, len(names) // 4))\n",
    "    bars = plt.barh(names, values, color=colors)\n",
    "\n",
    "    # Adding values on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height() / 2, f'{value}',\n",
    "                 va='center', ha='left')\n",
    "\n",
    "    plt.margins(y=0.01)\n",
    "    plt.xlabel('Appearances')\n",
    "    plt.ylabel('Skill')\n",
    "    plt.title(title)\n",
    "\n",
    "plot_reqs(musts, \"Must have skills appearances\", col=\"plasma\")\n",
    "plot_reqs(nices, \"Nice to have skill appearances\", col=\"viridis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {\n",
    "    \"programming languages\": [\n",
    "        \"Python\", \"SQL\", \"Java\", \"JavaScript\", \"TypeScript\", \n",
    "        \"C++\", \"C#\", \"HTML\", \"CSS\", \"Node.js\", \n",
    "        \"Golang\", \"Scala\", \"C\", \"PHP\"\n",
    "    ],\n",
    "    \"frameworks\": [\n",
    "        \"React\", \".NET\", \"Spring Boot\", \"Microservices\",\n",
    "        \"TensorFlow\", \"Angular\", \"Spring\"\n",
    "    ],\n",
    "    \"cloud technologies\": [\n",
    "        \"AWS\", \"Azure\", \"GCP\", \"Azure DevOps\"\n",
    "    ],\n",
    "    \"databases\": [\n",
    "        \"PostgreSQL\", \"MySQL\", \"Oracle\", \"NoSQL\", \"MongoDB\", \"Redis\"\n",
    "    ],\n",
    "    \"containerization and orchestration\": [\n",
    "        \"Docker\", \"Kubernetes\"\n",
    "    ],\n",
    "    \"configuration management and automation\": [\n",
    "        \"Ansible\", \"Terraform\"\n",
    "    ],\n",
    "    \"ci/cd\": [\n",
    "        \"Jenkins\", \"GitLab\", \"Azure DevOps\", \"DevOps\", \"CI/CD\", \"CI\"\n",
    "    ],\n",
    "    \"monitoring and logging\": [\n",
    "        \"Prometheus\", \"Grafana\", \"Elasticsearch\"\n",
    "    ],\n",
    "    \"messaging and streaming\": [\n",
    "        \"Kafka\", \"RabbitMQ\"\n",
    "    ],\n",
    "    \"scripting languages\": [\n",
    "        \"Bash\", \"PowerShell\"\n",
    "    ],\n",
    "    \"data processing\": [\n",
    "        \"ETL\", \"Spark\"\n",
    "    ],\n",
    "    \"other technologies\": [\n",
    "        \"Git\", \"Linux\", \"SAP\", \"AI\", \"GraphQL\", \"REST API\", \"REST\", \"Maven\"\n",
    "    ],\n",
    "    \"other\": [\n",
    "        \"Communication skills\", \"Project management\", \"Agile\", \"Degree\", \"Jira\", \"Confluence\"\n",
    "    ]\n",
    "}\n",
    "def plot_reqs_grouped(reqs, group, title, col=\"plasma\"):\n",
    "    counter = Counter([m[\"value\"] for m in reqs if m[\"value\"] in group])\n",
    "    names = sorted(list(counter), key=lambda x: -counter[x])[:50]\n",
    "    names = list(reversed(names))\n",
    "    values = [counter[name] for name in names]\n",
    "\n",
    "    if col == \"plasma\":\n",
    "        gradient = np.linspace(0, 0.7, len(names))\n",
    "        colors = plt.cm.plasma(gradient)\n",
    "    else:\n",
    "        gradient = np.linspace(0, 0.7, len(names))\n",
    "        colors = plt.cm.viridis(gradient)\n",
    "        \n",
    "    plt.figure(figsize=(12, len(group) // 2))\n",
    "    bars = plt.barh(names, values, color=colors)\n",
    "\n",
    "    # Adding values on bars\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height() / 2, f'{value}',\n",
    "                 va='center', ha='left')\n",
    "\n",
    "    plt.margins(y=0.01)\n",
    "    plt.xlabel('Appearances')\n",
    "    plt.ylabel('Skill')\n",
    "    plt.title(title)\n",
    "    \n",
    "    \n",
    "for name, skills in groups.items():\n",
    "    plot_reqs_grouped(musts, skills, f\"Must have {name} skills appearances\")\n",
    "    plot_reqs_grouped(nices, skills, f\"Nice to have {name} skills appearances\", col=\"viridis\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(langs), len(data), f\"\\nAvg lang per offer: {len(langs) / len(data):.3f}\\n\")\n",
    "counter = Counter([lang[\"code\"] for lang in langs])\n",
    "names = sorted(list(counter), key=lambda x: -counter[x])\n",
    "levels = [\"NA\", \"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\", \"NATIVE\"]\n",
    "table = [[level] + [len([lang for lang in langs if lang[\"code\"] == code and lang.get(\"level\", \"NA\") == level]) for code in names] for level in levels]\n",
    "table.append([\"Total\"] + [counter[x] for x in names])\n",
    "print(tabulate(table, headers=[\"\"] + names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Publication dates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_timestamps(timestamps, bins: int):\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    dates = [datetime.fromtimestamp(ts) for ts in timestamps]\n",
    "    ax1.hist(dates, bins=bins, rwidth=0.9)\n",
    "    dayFmt = mdates.DateFormatter('%m/%d')\n",
    "    ax1.xaxis.set_major_formatter(dayFmt)\n",
    "    ax1.set_xlabel('Publication date [month/day] in 2024')\n",
    "    ax1.set_ylabel('Number of occurances')\n",
    "    ax1.tick_params(axis='x', labelrotation=15)\n",
    "    ax1.set_title('Job offer publication date')\n",
    "    \n",
    "    times = [datetime.fromtimestamp(ts % (60*60*24)) for ts in timestamps]\n",
    "    ax2.hist(times, bins=bins, rwidth=0.9)\n",
    "    hourFmt = mdates.DateFormatter('%H:%M:%S')\n",
    "    ax2.xaxis.set_major_formatter(hourFmt)\n",
    "    ax2.set_xlabel('Publication time')\n",
    "    ax2.set_ylabel('Number of occurances')\n",
    "    ax2.tick_params(axis='x', labelrotation=15)\n",
    "    ax2.set_title('Job offer publication time of day')\n",
    "\n",
    "times = [item[\"posted\"] // 1000 for item in data]\n",
    "plot_timestamps(times, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "LOC_CACHE_PATH = 'location_cache.pkl'\n",
    "\n",
    "def geocode_addresses(addresses):\n",
    "    \"\"\"Returns a list of location data. Uses pickle cache to limit the number of OpenStreetMap requests.\"\"\"\n",
    "    cache = {}\n",
    "    if os.path.isfile(LOC_CACHE_PATH):\n",
    "        with open(LOC_CACHE_PATH, 'rb') as f:\n",
    "            cache = pickle.load(f)\n",
    "            print(f\"Loaded {len(cache)} locations from cache\")\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"http\")\n",
    "    location_data = {}\n",
    "    for address in addresses:\n",
    "        if address in cache:\n",
    "            location = cache[address]\n",
    "        else:\n",
    "            print(f\"{address}: geocoded\")\n",
    "            location = geolocator.geocode(address)\n",
    "            time.sleep(1) # as per requirement at https://operations.osmfoundation.org/policies/nominatim/\n",
    "            cache[address] = location\n",
    "            with open(LOC_CACHE_PATH, 'wb') as f:\n",
    "                pickle.dump(cache, f)\n",
    "            if location is None:\n",
    "                print(f\"Geocoding failed for: {address}\")\n",
    "        in_poland = location.raw['display_name'].endswith(\"Polska\")\n",
    "        location_data[address] = {'in_poland': in_poland, 'loc': [location.latitude, location.longitude]}\n",
    "    return location_data\n",
    "\n",
    "\n",
    "def plot_addresses_on_map(cnt, location_data, output_file='city_map.html'):\n",
    "    \"\"\"Generates an html file with an interactive worldmap.\"\"\"\n",
    "    center_of_poland = [51.9194, 19.1451]\n",
    "    total = sum(cnt.values())\n",
    "    map = folium.Map(location=center_of_poland, zoom_start=6)\n",
    "\n",
    "    for address, data in location_data.items():\n",
    "        in_poland, loc = data['in_poland'], data['loc']\n",
    "        occurances = cnt[address]\n",
    "        tooltip = f\"{address}: {occurances}\"\n",
    "        radius = max(2e3, occurances / total * 1e5)\n",
    "        folium.Circle(location=loc, radius=radius, fill=True, tooltip=tooltip,).add_to(map)\n",
    "        if not in_poland:\n",
    "            folium.Marker(location=loc, color=\"red\", tooltip=tooltip, icon=folium.Icon(icon=\"globe\", color=\"darkblue\")).add_to(map)\n",
    "\n",
    "    map.save(output_file)\n",
    "    print(f\"Map saved to {output_file}\")\n",
    "\n",
    "\n",
    "def get_city_cnt(data):\n",
    "    cities = []\n",
    "    for offer in data:\n",
    "        for place in offer['location']['places']:\n",
    "            if 'city' in place:\n",
    "                city = place['city'].capitalize()\n",
    "                if city == \"Bielsko - biała\":\n",
    "                    city = \"Bielsko-biała\"\n",
    "                if city == \"Warsaw\":\n",
    "                    city = \"Warszawa\"\n",
    "                if city == \"Lodz\":\n",
    "                    city = \"Łódź\"\n",
    "                if city == \"Gdansk\":\n",
    "                    city = \"Gdańsk\"\n",
    "                if city == \"Wroclaw\":\n",
    "                    city = \"Wrocław\"\n",
    "                if city == \"Poznan\":\n",
    "                    city = \"Poznań\"\n",
    "                if city in [\"Krakow\", \"Cracow\"]:\n",
    "                    city = \"Kraków\"\n",
    "                if city in [\"Poland\"]:\n",
    "                    continue\n",
    "                if city == \"Zabierzów k. krakowa\":\n",
    "                    city = \"Zabierzów\"\n",
    "                if city in [\"Remote\", \"Zdalnie\", \"Remotely pol\"]:\n",
    "                    city = \"Remote\"\n",
    "                cities.append(city)\n",
    "    return Counter(cities)\n",
    "\n",
    "cnt = get_city_cnt(data)\n",
    "del cnt[\"Remote\"]\n",
    "location_data = geocode_addresses(cnt.keys())\n",
    "plot_addresses_on_map(cnt, location_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benefits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benefits_synonym_inv_map = {\n",
    "    'Sport subscription': ['Sport Subscription', 'Multisport card', 'Multisport', ],\n",
    "    'Insurance': ['Life & group insurance', 'Insurance'],\n",
    "    'Language classes': ['English lessons'],\n",
    "    'Training budget': ['Trainings', ]\n",
    "}\n",
    "benefits_synonym_map = {syn: disambiguation for disambiguation, synset in benefits_synonym_inv_map.items() for syn in synset}\n",
    "\n",
    "\n",
    "def disambiguate_benefits(benefits: list[str]) -> list[str]:\n",
    "    return [benefits_synonym_map.get(b, b) for b in benefits]\n",
    "\n",
    "\n",
    "def get_benefits_and_office_perks() -> tuple[Counter, Counter]:\n",
    "    global data\n",
    "    benefits_counter = Counter()\n",
    "    office_perks_counter = Counter()\n",
    "    for item in data:\n",
    "        benefits = disambiguate_benefits(item['benefits']['benefits'])\n",
    "        office_perks = item['benefits']['officePerks']\n",
    "        benefits_counter += Counter(benefits)\n",
    "        office_perks_counter += Counter(office_perks)\n",
    "    return benefits_counter, office_perks_counter\n",
    "\n",
    "\n",
    "benefits_counter, office_perks_counter = get_benefits_and_office_perks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_benefits(benefit_counter, title, col=\"jet\", topn=16):\n",
    "    names = list(reversed(sorted(list(benefit_counter), key=lambda x: -benefit_counter[x])[:topn]))\n",
    "    values = [benefit_counter[name] for name in names]\n",
    "\n",
    "    if col == \"jet\":\n",
    "        gradient = np.linspace(0, 0.7, len(names))\n",
    "        colors = plt.cm.jet(gradient)\n",
    "    else:\n",
    "        gradient = np.linspace(0, 0.7, len(names))\n",
    "        colors = plt.cm.RdYlBu_r(gradient)\n",
    "    \n",
    "    plt.figure(figsize=(12, len(names) // 4))\n",
    "    bars = plt.barh(names, values, color=colors)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_width() + 1, bar.get_y() + bar.get_height() / 2, f'{value}',\n",
    "                 va='center', ha='left')\n",
    "\n",
    "    plt.margins(y=0.01)\n",
    "    plt.xlabel('Appearances')\n",
    "    plt.ylabel('Perk')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benefits(benefits_counter, title='Benefits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_benefits(office_perks_counter, title='Office Perks', col='RdYlBu_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Titles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_synonym_inv_map = {\n",
    "    'DevOps Engineer': ['Senior DevOps Engineer',],\n",
    "    'Data Engineer': ['Senior Data Engineer', ],\n",
    "    'Software Developer': ['Senior Software Engineer', ],\n",
    "    'Frontend Developer': ['Senior Frontend Developer', ],\n",
    "    'Product Manager': ['Senior Product Manager', ],\n",
    "    'Java Developer': ['Senior Java Developer', 'Java Software Engineer']\n",
    "}\n",
    "title_synonym_map = {syn: disambiguation for disambiguation, synset in title_synonym_inv_map.items() for syn in synset}\n",
    "\n",
    "def get_title_counter() -> Counter:\n",
    "    global data\n",
    "    title_counter = Counter()\n",
    "    for item in data:\n",
    "        title = title_synonym_map.get(item['title'], item['title'])\n",
    "        title_counter[title] += 1\n",
    "    return title_counter\n",
    "\n",
    "title_counter = get_title_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_titles(title_counter, topn=16):\n",
    "    names = list(reversed(sorted(list(title_counter), key=lambda x: -title_counter[x])[:topn]))\n",
    "    values = [title_counter[name] for name in names]\n",
    "\n",
    "    gradient = np.linspace(0, 0.7, len(names))\n",
    "    colors = plt.cm.inferno_r(gradient)\n",
    "    \n",
    "    plt.figure(figsize=(12, len(names) // 4))\n",
    "    bars = plt.barh(names, values, color=colors)\n",
    "\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height() / 2, f'{value}',\n",
    "                 va='center', ha='left')\n",
    "\n",
    "    plt.margins(y=0.01)\n",
    "    plt.xlabel('Appearances')\n",
    "    plt.ylabel('Title')\n",
    "    plt.title('Job Titles')\n",
    "\n",
    "plot_titles(title_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description word cloud**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements_desc_joined = \" \".join(item['requirements']['description'] for item in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_desc_joined = \" \".join(item['details']['description'] for item in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "stopwords = (\n",
    "    STOPWORDS | \n",
    "    {'li', 'ul', 'strong', 'p', 'w', 'b', 'br', 'h3', 'h2', 'h1', 'u', 'amp', 's'} |  # html (?)\n",
    "    {'się', 'tym', 'z', 'e.g.', 'eg', 'etc', 'np.', 'np', 'em', 'will', 'll', 'na', 'jak', 'jest', 're'}  # other stopwords\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "\n",
    "requirements_wordcloud = WordCloud(width=2400, height=1600, stopwords=stopwords, background_color=\"white\").generate(requirements_desc_joined)\n",
    "\n",
    "plt.figure(figsize=(18, 14))\n",
    "plt.imshow(requirements_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details\n",
    "\n",
    "details_wordcloud = WordCloud(width=2400, height=1600, stopwords=stopwords, background_color=\"white\").generate(details_desc_joined)\n",
    "\n",
    "plt.figure(figsize=(18, 14))\n",
    "plt.imshow(details_wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
